{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "325f617b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\shaikh\\anaconda3\\lib\\site-packages (4.10.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\shaikh\\anaconda3\\lib\\site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\shaikh\\anaconda3\\lib\\site-packages (from selenium) (0.22.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\shaikh\\anaconda3\\lib\\site-packages (from selenium) (0.10.3)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\shaikh\\anaconda3\\lib\\site-packages (from selenium) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\shaikh\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\shaikh\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\shaikh\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\shaikh\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\shaikh\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\shaikh\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\shaikh\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.1.2)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\shaikh\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\shaikh\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\shaikh\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\shaikh\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b22b8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: webdriver-manager in c:\\users\\shaikh\\anaconda3\\lib\\site-packages (3.8.6)\n",
      "Requirement already satisfied: requests in c:\\users\\shaikh\\anaconda3\\lib\\site-packages (from webdriver-manager) (2.29.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\shaikh\\anaconda3\\lib\\site-packages (from webdriver-manager) (1.0.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\shaikh\\anaconda3\\lib\\site-packages (from webdriver-manager) (4.65.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\shaikh\\anaconda3\\lib\\site-packages (from webdriver-manager) (23.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shaikh\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shaikh\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\shaikh\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shaikh\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2023.5.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\shaikh\\anaconda3\\lib\\site-packages (from tqdm->webdriver-manager) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cc30885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\shaikh\\anaconda3\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\shaikh\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\shaikh\\anaconda3\\lib\\site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\shaikh\\anaconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\shaikh\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce29b233",
   "metadata": {},
   "source": [
    "# Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10\n",
    "jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0086a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dcb2421",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By \n",
    "import time\n",
    "from selenium.webdriver.chrome.service import Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f95b9473",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the driver\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "59ab7b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the naukri page on the automated chrome browser\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0a5221a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entering the designaiion\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "designation.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9f159767",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entering the Location\n",
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/div[1]/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "904d1015",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for the query\n",
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "331fab0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f7666e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping Job title\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "#scrapping job location\n",
    "location_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "#scrapping company name\n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "#scrapping experience required\n",
    "exp_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "for i in exp_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "92c5b49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "#Printing the length of the titles\n",
    "\n",
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "862eb3f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Eastvantage</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/ Bengaluru, Karnataka, Gurgaon/ Guru...</td>\n",
       "      <td>Delhivery</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Everest Vacuum</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad, Pune</td>\n",
       "      <td>Synechron</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad, Pune</td>\n",
       "      <td>Synchron Infotech</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>ANZ</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst I</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Cerner</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Persolkelly India</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Paychex It Solutions</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, New Delh...</td>\n",
       "      <td>Truthfools</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Title                                           Location  \\\n",
       "0    Data Analyst                                Bangalore/Bengaluru   \n",
       "1    Data Analyst  Bangalore/ Bengaluru, Karnataka, Gurgaon/ Guru...   \n",
       "2    Data Analyst                                Bangalore/Bengaluru   \n",
       "3    Data Analyst  Bangalore/Bengaluru, Hyderabad/Secunderabad, Pune   \n",
       "4    Data Analyst  Bangalore/Bengaluru, Hyderabad/Secunderabad, Pune   \n",
       "5    Data Analyst                                Bangalore/Bengaluru   \n",
       "6  Data Analyst I                                Bangalore/Bengaluru   \n",
       "7    Data Analyst                                Bangalore/Bengaluru   \n",
       "8    Data Analyst                                Bangalore/Bengaluru   \n",
       "9    Data Analyst  Bangalore/Bengaluru, Kolkata, Mumbai, New Delh...   \n",
       "\n",
       "           Company_Name Experience  \n",
       "0           Eastvantage    4-6 Yrs  \n",
       "1             Delhivery    1-3 Yrs  \n",
       "2        Everest Vacuum    2-5 Yrs  \n",
       "3             Synechron    5-8 Yrs  \n",
       "4     Synchron Infotech    5-8 Yrs  \n",
       "5                   ANZ    1-5 Yrs  \n",
       "6                Cerner   5-10 Yrs  \n",
       "7     Persolkelly India    0-2 Yrs  \n",
       "8  Paychex It Solutions    3-8 Yrs  \n",
       "9            Truthfools    3-8 Yrs  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Dataframe using Pandas\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'Title':job_title,'Location':job_location,'Company_Name':company_name,'Experience':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de16724",
   "metadata": {},
   "source": [
    "# Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6aa6a50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import all required libraries\n",
    "import selenium                                  #library that is used to work with selenium\n",
    "from selenium import webdriver                   #importing webdriver module from selenium to open automated chrome window\n",
    "import pandas as pd                              #to create DataFrame\n",
    "from selenium.webdriver.common.by import By      #importing inbuilt class By \n",
    "import warnings                                  #to ignore any sort of warning\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time                                      #use to stop search engine for few seconds\n",
    "\n",
    "driver = webdriver.Chrome()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "688a6ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the naukri page on the automated chrome browser\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d734095",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering the designation and location\n",
    "designation2=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation2.send_keys(\"Data Scientist\")\n",
    "\n",
    "location2=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/div[1]/div/input\")\n",
    "location2.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da2341cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55950c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "Job_title=[]\n",
    "Job_location=[]\n",
    "Company_name=[]\n",
    "Experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b327f8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Job title from the page\n",
    "title1_tags=driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in title1_tags[0:10]:\n",
    "    title=i.text\n",
    "    Job_title.append(title)\n",
    "    \n",
    "#scrapping Job location   \n",
    "location1_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location1_tags[0:10]:\n",
    "    loc=i.text\n",
    "    Job_location.append(loc)\n",
    "\n",
    "#scrapping Company Name    \n",
    "company1_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company1_tags[0:10]:\n",
    "    company=i.text\n",
    "    Company_name.append(company)\n",
    "    \n",
    "#scrapping Experience required\n",
    "exp1_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "for i in exp1_tags[0:10]:\n",
    "    experience=i.text\n",
    "    Experience_required.append(experience)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "21fdf071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "#Printing the length of the titles\n",
    "\n",
    "print(len(Job_title),len(Job_location),len(Company_name),len(Experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "17ced273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Job location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai (All Areas)</td>\n",
       "      <td>PwC</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist -ML, DL, Python</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Capco</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DATA SCIENTIST</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Hybrid - Bangalore/ Bengaluru, Karnataka, Noid...</td>\n",
       "      <td>HCLTech</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACN - Applied Intelligence - Finance - Data Sc...</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad, P...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sr . Data Scientist / Manager</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Gurgaon/Gurugram</td>\n",
       "      <td>Novitas Infotech</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Gurgaon/Gurugram</td>\n",
       "      <td>Novitas Infotech</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                            Data Science Specialist   \n",
       "1                                     Data Scientist   \n",
       "2                   Analystics & Modeling Specialist   \n",
       "3                     Data Scientist -ML, DL, Python   \n",
       "4                                     DATA SCIENTIST   \n",
       "5                                     Data Scientist   \n",
       "6  ACN - Applied Intelligence - Finance - Data Sc...   \n",
       "7                              Senior Data Scientist   \n",
       "8                      Sr . Data Scientist / Manager   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                                        Job location       Company Name  \\\n",
       "0  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...          Accenture   \n",
       "1            Bangalore/Bengaluru, Mumbai (All Areas)                PwC   \n",
       "2  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...          Accenture   \n",
       "3                                Bangalore/Bengaluru              Capco   \n",
       "4                                Bangalore/Bengaluru            Walmart   \n",
       "5  Hybrid - Bangalore/ Bengaluru, Karnataka, Noid...            HCLTech   \n",
       "6  Bangalore/Bengaluru, Hyderabad/Secunderabad, P...          Accenture   \n",
       "7                        Bangalore/Bengaluru, Mumbai  Fractal Analytics   \n",
       "8       Bangalore/Bengaluru, Noida, Gurgaon/Gurugram   Novitas Infotech   \n",
       "9       Bangalore/Bengaluru, Noida, Gurgaon/Gurugram   Novitas Infotech   \n",
       "\n",
       "  Experience  \n",
       "0    2-4 Yrs  \n",
       "1    3-6 Yrs  \n",
       "2    6-8 Yrs  \n",
       "3    2-6 Yrs  \n",
       "4    4-8 Yrs  \n",
       "5   7-12 Yrs  \n",
       "6    2-7 Yrs  \n",
       "7   5-10 Yrs  \n",
       "8   7-10 Yrs  \n",
       "9    3-7 Yrs  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating dataframe from pandas\n",
    "df1=pd.DataFrame({\"Title\":Job_title,\"Job location\":Job_location,\"Company Name\":Company_name,\"Experience\":Experience_required})\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd4fe5e",
   "metadata": {},
   "source": [
    "# Q3: In this question you have to scrape data using the filters available on the webpage as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3e5a5456",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets import all libraries\n",
    "import selenium                #Library that is used to work with selenium\n",
    "from selenium import webdriver #importing webdriver module from selenium to open automated chrome window\n",
    "import pandas as pd            #for creating DataFrame\n",
    "from selenium.webdriver.common.by import By  #importing inbuilt class by\n",
    "import warnings                #to ignore any sort of warning\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "28264e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the naukri page in the automated driver page\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "63da7fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entering the designation\n",
    "designation2=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation2.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ff7f4c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "51fc2afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(10)  # time taken for load of page "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f9db3e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The location filter to be used is “Delhi/NCR”. \n",
    "location_filter=driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/div/section[1]/div[2]/div[5]/div[2]/div[2]/label/p/span[1]\")\n",
    "location_filter.click()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4c4347e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#salary filter\n",
    "salary_filter=driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/div/section[1]/div[2]/div[6]/div[2]/div[2]/label/p/span[1]\")\n",
    "salary_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "24dbf2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "JOB_title=[]\n",
    "JOB_location=[]\n",
    "COMPANY_name=[]\n",
    "REQ_experience=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b3b327db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the job title from the page\n",
    "title3_tags=driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in title3_tags[0:10]:\n",
    "    title=i.text\n",
    "    JOB_title.append(title)\n",
    "    \n",
    "location3_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location3_tags[0:10]:\n",
    "    loc=i.text\n",
    "    JOB_location.append(loc)\n",
    "    \n",
    "company3_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company3_tags[0:10]:\n",
    "    company3=i.text\n",
    "    COMPANY_name.append(company3)\n",
    "    \n",
    "exp_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "for i in exp_tags[0:10]:\n",
    "    exp3=i.text\n",
    "    REQ_experience.append(exp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6b461515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(JOB_title),len(JOB_location),len(COMPANY_name),len(REQ_experience))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5a6d6666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Compnay Name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...</td>\n",
       "      <td>Analytos</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Blackbuck</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist/ Senior Data Scientist/ Manager...</td>\n",
       "      <td>Noida, Kolkata, Mumbai, Chandigarh, Hyderabad/...</td>\n",
       "      <td>Dreambig It Solutions India</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...</td>\n",
       "      <td>Analytos</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Times Internet</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Python and ML Trainer</td>\n",
       "      <td>Hyderabad/Secunderabad, New Delhi, Pune, Gurga...</td>\n",
       "      <td>Thescholar</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Intern</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Tower Research Capital</td>\n",
       "      <td>0-1 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hiring For Data Scientist</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Infogain</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram, United States (USA), Bulgaria</td>\n",
       "      <td>Adidas</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Associate Data Scientist - ML &amp; NLP</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Gartner</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job title  \\\n",
       "0                              Junior Data Scientist   \n",
       "1                                     Data Scientist   \n",
       "2  Data Scientist/ Senior Data Scientist/ Manager...   \n",
       "3                                     Data Scientist   \n",
       "4                                     Data Scientist   \n",
       "5                              Python and ML Trainer   \n",
       "6                                             Intern   \n",
       "7                          Hiring For Data Scientist   \n",
       "8                              Junior Data Scientist   \n",
       "9                Associate Data Scientist - ML & NLP   \n",
       "\n",
       "                                            Location  \\\n",
       "0  Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...   \n",
       "1              Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "2  Noida, Kolkata, Mumbai, Chandigarh, Hyderabad/...   \n",
       "3  Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...   \n",
       "4                                              Noida   \n",
       "5  Hyderabad/Secunderabad, New Delhi, Pune, Gurga...   \n",
       "6                                   Gurgaon/Gurugram   \n",
       "7                                             Remote   \n",
       "8    Gurgaon/Gurugram, United States (USA), Bulgaria   \n",
       "9                                   Gurgaon/Gurugram   \n",
       "\n",
       "                  Compnay Name Experience  \n",
       "0                     Analytos    0-2 Yrs  \n",
       "1                    Blackbuck    3-7 Yrs  \n",
       "2  Dreambig It Solutions India    1-6 Yrs  \n",
       "3                     Analytos    2-4 Yrs  \n",
       "4               Times Internet    3-8 Yrs  \n",
       "5                   Thescholar    3-8 Yrs  \n",
       "6       Tower Research Capital    0-1 Yrs  \n",
       "7                     Infogain    4-9 Yrs  \n",
       "8                       Adidas    1-6 Yrs  \n",
       "9                      Gartner    2-4 Yrs  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating the Dataframe\n",
    "\n",
    "df3=pd.DataFrame({'Job title':JOB_title,'Location':JOB_location,'Compnay Name':COMPANY_name,'Experience':REQ_experience})\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c11f696",
   "metadata": {},
   "source": [
    "# Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4ba5e6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error getting version of chromedriver 115. Retrying with chromedriver 114 (attempt 1/5)\n"
     ]
    }
   ],
   "source": [
    "#lets import all libraries\n",
    "import pandas as pd\n",
    "import selenium      #Library that is used to work with selenium\n",
    "from selenium import webdriver  #importing webdriver module from selenium to open automated chrome window\n",
    "from selenium.webdriver.common.by import By  #importing inbuilt class by\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "593f06ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the flipkart page in automated driver page\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4e86c01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entering the sunglasses \n",
    "product=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "product.send_keys(\"Sunglasses\")\n",
    "\n",
    "search=driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cf7d9b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrapping the data in same lenth selecting the f-assured\n",
    "fassured_search=driver.find_element(By.XPATH,'//div[@class=\"_3U-Vxu\"]')\n",
    "fassured_search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a81b1c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping the data for the sunglasses\n",
    "Sunglasses_Brand=[]\n",
    "Product_Description=[]\n",
    "Price=[]\n",
    "\n",
    "\n",
    "start=0\n",
    "end=4\n",
    "for page in range(start,end):\n",
    "    Brand_tags=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for i in Brand_tags[0:100]:\n",
    "        product=i.text\n",
    "        Sunglasses_Brand.append(product)\n",
    "        \n",
    "    Product_tags=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    for i in Product_tags[0:100]:\n",
    "        product1=i.text\n",
    "        Product_Description.append(product1)\n",
    "        \n",
    "    Price_tags=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for i in Price_tags[0:100]:\n",
    "        price1=i.text\n",
    "        Price.append(price1)\n",
    "\n",
    "        \n",
    "    try:\n",
    "        next_button=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div/div[2]/div[12]/div/div/nav/a[11]')\n",
    "        next_button.click()\n",
    "        time.sleep(8)\n",
    "    except NoSuchElementException:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c5393b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 160 160\n"
     ]
    }
   ],
   "source": [
    "print(len(Sunglasses_Brand),len(Product_Description),len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "dc307e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sunglasses Brands</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IRUS</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (52)</td>\n",
       "      <td>₹531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LOUIS KOUROS</td>\n",
       "      <td>UV Protection, Riding Glasses, Mirrored Aviato...</td>\n",
       "      <td>₹1,343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SDEEP</td>\n",
       "      <td>UV Protection, Others Spectacle Sunglasses (Fr...</td>\n",
       "      <td>₹185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (50)</td>\n",
       "      <td>₹194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Rich Club</td>\n",
       "      <td>Polarized, UV Protection, Riding Glasses Wayfa...</td>\n",
       "      <td>₹365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection Oval Sunglasses (Free Size)</td>\n",
       "      <td>₹400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ROZIOR</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (40)</td>\n",
       "      <td>₹349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Polarized, UV Protection Round Sunglasses (50)</td>\n",
       "      <td>₹664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Sukart</td>\n",
       "      <td>Riding Glasses, Others Oval, Wayfarer, Cat-eye...</td>\n",
       "      <td>₹292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sunglasses Brands                                Product Description  \\\n",
       "0               IRUS             UV Protection Wayfarer Sunglasses (52)   \n",
       "1       LOUIS KOUROS  UV Protection, Riding Glasses, Mirrored Aviato...   \n",
       "2              SDEEP  UV Protection, Others Spectacle Sunglasses (Fr...   \n",
       "3               SRPM             UV Protection Wayfarer Sunglasses (50)   \n",
       "4           Fastrack   UV Protection Rectangular Sunglasses (Free Size)   \n",
       "..               ...                                                ...   \n",
       "95         Rich Club  Polarized, UV Protection, Riding Glasses Wayfa...   \n",
       "96    ROZZETTA CRAFT          UV Protection Oval Sunglasses (Free Size)   \n",
       "97            ROZIOR             UV Protection Wayfarer Sunglasses (40)   \n",
       "98         ROYAL SON     Polarized, UV Protection Round Sunglasses (50)   \n",
       "99            Sukart  Riding Glasses, Others Oval, Wayfarer, Cat-eye...   \n",
       "\n",
       "     Price  \n",
       "0     ₹531  \n",
       "1   ₹1,343  \n",
       "2     ₹185  \n",
       "3     ₹194  \n",
       "4     ₹675  \n",
       "..     ...  \n",
       "95    ₹365  \n",
       "96    ₹400  \n",
       "97    ₹349  \n",
       "98    ₹664  \n",
       "99    ₹292  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the Dataframe by slicing the data to top 100 sunglasses\n",
    "df4=pd.DataFrame({\"Sunglasses Brands\":Sunglasses_Brand,\"Product Description\":Product_Description,\"Price\":Price})\n",
    "\n",
    "New_df4=df4.iloc[0:100]\n",
    "New_df4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40459032",
   "metadata": {},
   "source": [
    "# Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "fd60e0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets import all libraries\n",
    "import pandas as pd\n",
    "import selenium      #Library that is used to work with selenium\n",
    "from selenium import webdriver  #importing webdriver module from selenium to open automated chrome window\n",
    "from selenium.webdriver.common.by import By  #importing inbuilt class by\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b3160c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets import the Website\n",
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-purple-64-gb/product-reviews/itm2b8d03427ddac?pid=MOBFWQ6BTFFJKGKE&lid=LSTMOBFWQ6BTFFJKGKEPGQVOJ&marketplace=FLIPKART\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "bcd0af3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rating=[]\n",
    "Review_Summary=[]\n",
    "Full_review=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "fbe3f90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping the rating,review summary and full review of top 100\n",
    "start=0\n",
    "end=10\n",
    "# Find all the rating tags on the current page\n",
    "for page in range(start,end):\n",
    "    rating_tags=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for i in rating_tags:\n",
    "        Rating.append(i.text)\n",
    "        \n",
    "# Scrape data from the current page and append it to the 'Review_Summary' list\n",
    "    review_tags=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for i in review_tags:\n",
    "        Review_Summary.append(i.text)\n",
    "# Find all the full review tags on the current page\n",
    "    Summary_tags=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "    for i in Summary_tags:\n",
    "        Full_review.append(i.text)\n",
    "    try:        \n",
    "        next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "        next_button.click()\n",
    "        time.sleep(4)\n",
    "    except nosuchelement:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "703edab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(Rating),len(Review_Summary),len(Full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "bf87a953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Summary</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>Very very good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>Camera is awesome\\nBest battery backup\\nA perf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>Excellent Phone.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>This is amazing at all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Must buy!</td>\n",
       "      <td>It’s really awesome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Buy it if you afford it 😜</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Best camera ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>Value for money 🖤🖤</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>I dreamt about this day from a long time.... G...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating     Review Summary  \\\n",
       "0       5           Terrific   \n",
       "1       5     Classy product   \n",
       "2       5          Brilliant   \n",
       "3       5          Wonderful   \n",
       "4       5          Must buy!   \n",
       "..    ...                ...   \n",
       "95      5     Simply awesome   \n",
       "96      5          Excellent   \n",
       "97      5  Terrific purchase   \n",
       "98      5     Simply awesome   \n",
       "99      5            Awesome   \n",
       "\n",
       "                                          Full Review  \n",
       "0                                      Very very good  \n",
       "1   Camera is awesome\\nBest battery backup\\nA perf...  \n",
       "2                                    Excellent Phone.  \n",
       "3                              This is amazing at all  \n",
       "4                                 It’s really awesome  \n",
       "..                                                ...  \n",
       "95                          Buy it if you afford it 😜  \n",
       "96                                   Best camera ever  \n",
       "97                                 Value for money 🖤🖤  \n",
       "98  Really satisfied with the Product I received.....  \n",
       "99  I dreamt about this day from a long time.... G...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating Dataframe for the top 100 reviews on iphone\n",
    "\n",
    "df5=pd.DataFrame({'Rating':Rating,'Review Summary':Review_Summary,'Full Review':Full_review})\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e78943b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rating         Review Summary  \\\n",
      "0       5               Terrific   \n",
      "1       5         Classy product   \n",
      "2       5              Brilliant   \n",
      "3       5              Wonderful   \n",
      "4       5              Must buy!   \n",
      "5       5              Just wow!   \n",
      "6       5       Perfect product!   \n",
      "7       5  Mind-blowing purchase   \n",
      "8       5              Fabulous!   \n",
      "9       5    Best in the market!   \n",
      "10      5      Worth every penny   \n",
      "11      5      Terrific purchase   \n",
      "12      5              Fabulous!   \n",
      "13      5          Great product   \n",
      "14      5              Must buy!   \n",
      "15      5         Simply awesome   \n",
      "16      5              Excellent   \n",
      "17      5      Terrific purchase   \n",
      "18      5         Simply awesome   \n",
      "19      5                Awesome   \n",
      "20      5               Terrific   \n",
      "21      5         Classy product   \n",
      "22      5              Brilliant   \n",
      "23      5              Wonderful   \n",
      "24      5              Must buy!   \n",
      "25      5              Just wow!   \n",
      "26      5       Perfect product!   \n",
      "27      5  Mind-blowing purchase   \n",
      "28      5              Fabulous!   \n",
      "29      5    Best in the market!   \n",
      "30      5      Worth every penny   \n",
      "31      5      Terrific purchase   \n",
      "32      5              Fabulous!   \n",
      "33      5          Great product   \n",
      "34      5              Must buy!   \n",
      "35      5         Simply awesome   \n",
      "36      5              Excellent   \n",
      "37      5      Terrific purchase   \n",
      "38      5         Simply awesome   \n",
      "39      5                Awesome   \n",
      "40      5               Terrific   \n",
      "41      5         Classy product   \n",
      "42      5              Brilliant   \n",
      "43      5              Wonderful   \n",
      "44      5              Must buy!   \n",
      "45      5              Just wow!   \n",
      "46      5       Perfect product!   \n",
      "47      5  Mind-blowing purchase   \n",
      "48      5              Fabulous!   \n",
      "49      5    Best in the market!   \n",
      "50      5      Worth every penny   \n",
      "51      5      Terrific purchase   \n",
      "52      5              Fabulous!   \n",
      "53      5          Great product   \n",
      "54      5              Must buy!   \n",
      "55      5         Simply awesome   \n",
      "56      5              Excellent   \n",
      "57      5      Terrific purchase   \n",
      "58      5         Simply awesome   \n",
      "59      5                Awesome   \n",
      "60      5               Terrific   \n",
      "61      5         Classy product   \n",
      "62      5              Brilliant   \n",
      "63      5              Wonderful   \n",
      "64      5              Must buy!   \n",
      "65      5              Just wow!   \n",
      "66      5       Perfect product!   \n",
      "67      5  Mind-blowing purchase   \n",
      "68      5              Fabulous!   \n",
      "69      5    Best in the market!   \n",
      "70      5      Worth every penny   \n",
      "71      5      Terrific purchase   \n",
      "72      5              Fabulous!   \n",
      "73      5          Great product   \n",
      "74      5              Must buy!   \n",
      "75      5         Simply awesome   \n",
      "76      5              Excellent   \n",
      "77      5      Terrific purchase   \n",
      "78      5         Simply awesome   \n",
      "79      5                Awesome   \n",
      "80      5               Terrific   \n",
      "81      5         Classy product   \n",
      "82      5              Brilliant   \n",
      "83      5              Wonderful   \n",
      "84      5              Must buy!   \n",
      "85      5              Just wow!   \n",
      "86      5       Perfect product!   \n",
      "87      5  Mind-blowing purchase   \n",
      "88      5              Fabulous!   \n",
      "89      5    Best in the market!   \n",
      "90      5      Worth every penny   \n",
      "91      5      Terrific purchase   \n",
      "92      5              Fabulous!   \n",
      "93      5          Great product   \n",
      "94      5              Must buy!   \n",
      "95      5         Simply awesome   \n",
      "96      5              Excellent   \n",
      "97      5      Terrific purchase   \n",
      "98      5         Simply awesome   \n",
      "99      5                Awesome   \n",
      "\n",
      "                                          Full Review  \n",
      "0                                      Very very good  \n",
      "1   Camera is awesome\\nBest battery backup\\nA perf...  \n",
      "2                                    Excellent Phone.  \n",
      "3                              This is amazing at all  \n",
      "4                                 It’s really awesome  \n",
      "5                                   Perfect Product!!  \n",
      "6                                          V Good all  \n",
      "7                                        Photos super  \n",
      "8                     Super🔥 and good performance 👌❤️  \n",
      "9                                         Good Camera  \n",
      "10  Feeling awesome after getting the delivery of ...  \n",
      "11                                  Value for money 😍  \n",
      "12  It’s very good battery life and display and vi...  \n",
      "13                                     Purple is best  \n",
      "14  Go for iPhone 11 , if confused between iPhone ...  \n",
      "15                          Buy it if you afford it 😜  \n",
      "16                                   Best camera ever  \n",
      "17                                 Value for money 🖤🖤  \n",
      "18  Really satisfied with the Product I received.....  \n",
      "19  I dreamt about this day from a long time.... G...  \n",
      "20                                     Very very good  \n",
      "21  Camera is awesome\\nBest battery backup\\nA perf...  \n",
      "22                                   Excellent Phone.  \n",
      "23                             This is amazing at all  \n",
      "24                                It’s really awesome  \n",
      "25                                  Perfect Product!!  \n",
      "26                                         V Good all  \n",
      "27                                       Photos super  \n",
      "28                    Super🔥 and good performance 👌❤️  \n",
      "29                                        Good Camera  \n",
      "30  Feeling awesome after getting the delivery of ...  \n",
      "31                                  Value for money 😍  \n",
      "32  It’s very good battery life and display and vi...  \n",
      "33                                     Purple is best  \n",
      "34  Go for iPhone 11 , if confused between iPhone ...  \n",
      "35                          Buy it if you afford it 😜  \n",
      "36                                   Best camera ever  \n",
      "37                                 Value for money 🖤🖤  \n",
      "38  Really satisfied with the Product I received.....  \n",
      "39  I dreamt about this day from a long time.... G...  \n",
      "40                                     Very very good  \n",
      "41  Camera is awesome\\nBest battery backup\\nA perf...  \n",
      "42                                   Excellent Phone.  \n",
      "43                             This is amazing at all  \n",
      "44                                It’s really awesome  \n",
      "45                                  Perfect Product!!  \n",
      "46                                         V Good all  \n",
      "47                                       Photos super  \n",
      "48                    Super🔥 and good performance 👌❤️  \n",
      "49                                        Good Camera  \n",
      "50  Feeling awesome after getting the delivery of ...  \n",
      "51                                  Value for money 😍  \n",
      "52  It’s very good battery life and display and vi...  \n",
      "53                                     Purple is best  \n",
      "54  Go for iPhone 11 , if confused between iPhone ...  \n",
      "55                          Buy it if you afford it 😜  \n",
      "56                                   Best camera ever  \n",
      "57                                 Value for money 🖤🖤  \n",
      "58  Really satisfied with the Product I received.....  \n",
      "59  I dreamt about this day from a long time.... G...  \n",
      "60                                     Very very good  \n",
      "61  Camera is awesome\\nBest battery backup\\nA perf...  \n",
      "62                                   Excellent Phone.  \n",
      "63                             This is amazing at all  \n",
      "64                                It’s really awesome  \n",
      "65                                  Perfect Product!!  \n",
      "66                                         V Good all  \n",
      "67                                       Photos super  \n",
      "68                    Super🔥 and good performance 👌❤️  \n",
      "69                                        Good Camera  \n",
      "70  Feeling awesome after getting the delivery of ...  \n",
      "71                                  Value for money 😍  \n",
      "72  It’s very good battery life and display and vi...  \n",
      "73                                     Purple is best  \n",
      "74  Go for iPhone 11 , if confused between iPhone ...  \n",
      "75                          Buy it if you afford it 😜  \n",
      "76                                   Best camera ever  \n",
      "77                                 Value for money 🖤🖤  \n",
      "78  Really satisfied with the Product I received.....  \n",
      "79  I dreamt about this day from a long time.... G...  \n",
      "80                                     Very very good  \n",
      "81  Camera is awesome\\nBest battery backup\\nA perf...  \n",
      "82                                   Excellent Phone.  \n",
      "83                             This is amazing at all  \n",
      "84                                It’s really awesome  \n",
      "85                                  Perfect Product!!  \n",
      "86                                         V Good all  \n",
      "87                                       Photos super  \n",
      "88                    Super🔥 and good performance 👌❤️  \n",
      "89                                        Good Camera  \n",
      "90  Feeling awesome after getting the delivery of ...  \n",
      "91                                  Value for money 😍  \n",
      "92  It’s very good battery life and display and vi...  \n",
      "93                                     Purple is best  \n",
      "94  Go for iPhone 11 , if confused between iPhone ...  \n",
      "95                          Buy it if you afford it 😜  \n",
      "96                                   Best camera ever  \n",
      "97                                 Value for money 🖤🖤  \n",
      "98  Really satisfied with the Product I received.....  \n",
      "99  I dreamt about this day from a long time.... G...  \n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "print(df5)\n",
    "pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca86141",
   "metadata": {},
   "source": [
    "# Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the\n",
    "search field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7e6779d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets import all libraries\n",
    "import pandas as pd\n",
    "import selenium      #Library that is used to work with selenium\n",
    "from selenium import webdriver  #importing webdriver module from selenium to open automated chrome window\n",
    "from selenium.webdriver.common.by import By  #importing inbuilt class by\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "62c7ea18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the flipkart page in automated driver page\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6dfd9d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching for the sneakeers\n",
    "brand=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "brand.send_keys(\"Sneakers\")\n",
    "\n",
    "search=driver.find_element(By.CLASS_NAME,'L0Z3Pu')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "11c0911f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for proper length of the DataFrame select one filter parameter so selecting the f-assured filter for same length\n",
    "filter_tags=driver.find_element(By.CLASS_NAME,'_3U-Vxu')\n",
    "filter_tags.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2d796d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping the Brand,Product description and price of top 100 Sneakers\n",
    "Brand=[]\n",
    "Product_Description=[]\n",
    "Price=[] \n",
    "\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):\n",
    "    brand_tags=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for i in brand_tags:\n",
    "        Brand.append(i.text)\n",
    "        \n",
    "    Product_tags=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    for i in Product_tags:\n",
    "        Product_Description.append(i.text)\n",
    "        \n",
    "    Price_tags=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for i in Price_tags:\n",
    "        Price.append(i.text)\n",
    "        \n",
    "    try:\n",
    "        next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "        next_button.click()\n",
    "        time.sleep(10)\n",
    "    except NoSuchElement:\n",
    "        break\n",
    "                                                                                                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0fffdb6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 120 120\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand),len(Product_Description),len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7f3765b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brands</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Airson</td>\n",
       "      <td>Junior Zero1 Sports shoes for Men | Gym Traini...</td>\n",
       "      <td>₹989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sparx</td>\n",
       "      <td>Stylish and Comfirtable Shoes For Mens Sneaker...</td>\n",
       "      <td>₹899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Synthetic Leather |Lightweight|Comfort|Summer|...</td>\n",
       "      <td>₹387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Modern Trendy Shoes Sneakers For Men</td>\n",
       "      <td>₹299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Magnolia</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Nobelite</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>HIGHLANDER</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>RapidBox</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Free Kicks</td>\n",
       "      <td>Combo Of 2 Leather Shoes FK-310 and FK-Alpha P...</td>\n",
       "      <td>₹999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>asian</td>\n",
       "      <td>SM-162 Black Walking ,Training,Sneakers,Loafer...</td>\n",
       "      <td>₹499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Brands                                Product Description Price\n",
       "0       Airson  Junior Zero1 Sports shoes for Men | Gym Traini...  ₹989\n",
       "1        Sparx  Stylish and Comfirtable Shoes For Mens Sneaker...  ₹899\n",
       "2         aadi  Synthetic Leather |Lightweight|Comfort|Summer|...  ₹387\n",
       "3       BRUTON               Modern Trendy Shoes Sneakers For Men  ₹299\n",
       "4     Magnolia                                   Sneakers For Men  ₹299\n",
       "..         ...                                                ...   ...\n",
       "95    Nobelite                                   Sneakers For Men  ₹469\n",
       "96  HIGHLANDER                                   Sneakers For Men  ₹995\n",
       "97    RapidBox                                   Sneakers For Men  ₹695\n",
       "98  Free Kicks  Combo Of 2 Leather Shoes FK-310 and FK-Alpha P...  ₹999\n",
       "99       asian  SM-162 Black Walking ,Training,Sneakers,Loafer...  ₹499\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the Dataframe of top 100 sneakers by silcing the data\n",
    "df6=pd.DataFrame({\"Brands\":Brand,\"Product Description\":Product_Description,\"Price\":Price})\n",
    "\n",
    "New_df6=df6.iloc[0:100]\n",
    "New_df6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a690fe0",
   "metadata": {},
   "source": [
    "# Q7: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. Then\n",
    "set CPU Type filter to “Intel Core i7” as shown in the below image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bbd64e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets import all libraries\n",
    "import pandas as pd\n",
    "import selenium      #Library that is used to work with selenium\n",
    "from selenium import webdriver  #importing webdriver module from selenium to open automated chrome window\n",
    "from selenium.webdriver.common.by import By  #importing inbuilt class by\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daa5b3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Opening the amazon page in automated driver page\n",
    "driver.get(\"https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "873c2320",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcf1aa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching for the laptop\n",
    "lap=driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input\")\n",
    "lap.send_keys(\"Laptop\")\n",
    "\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bc86e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The CPU filter\n",
    "CPU=driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[6]/ul[7]/span[13]/li/span/a/span\")\n",
    "CPU.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "082886d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "Title=[]\n",
    "Ratings=[]\n",
    "Price=[]\n",
    "\n",
    "#Scrapping the title of laptop\n",
    "title_tags=driver.find_elements(By.XPATH,'//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    LP=i.text\n",
    "    Title.append(LP)\n",
    "    \n",
    "#Scrapping the Ratings of Laptop    \n",
    "rate_tags=driver.find_elements(By.XPATH,'//i[@class=\"a-icon a-icon-star-small a-star-small-4 aok-align-bottom\"]')\n",
    "for i in rate_tags[0:10]:\n",
    "    rate=i.text\n",
    "    Ratings.append(rate)\n",
    "\n",
    "#scapping the Price of Laptops\n",
    "price_tags=driver.find_elements(By.XPATH,'//span[@class=\"a-price-whole\"]')\n",
    "for i in price_tags[0:10]:\n",
    "    price=i.text\n",
    "    Price.append(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d69f195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "#printing the length of dataset\n",
    "print(len(Title),len(Ratings),len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "911537da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title of Laptops</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dell Inspiron 5430 13th Gen Laptop, Intel i7-1...</td>\n",
       "      <td></td>\n",
       "      <td>86,420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HP Pavilion 14, 11Th Gen Intel Core I7-16Gb Ra...</td>\n",
       "      <td></td>\n",
       "      <td>79,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenovo [SmartChoice] IdeaPad Slim 3 Intel Core...</td>\n",
       "      <td></td>\n",
       "      <td>62,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lenovo IdeaPad Gaming 3 Intel Core i7-12700H 1...</td>\n",
       "      <td></td>\n",
       "      <td>98,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MSI GF63 Thin, Intel Core i7-11800H, 40CM FHD ...</td>\n",
       "      <td></td>\n",
       "      <td>71,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Acer Nitro 5 AN515-58 Gaming Laptop 12th Gen I...</td>\n",
       "      <td></td>\n",
       "      <td>1,04,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dell Vostro 5630 13th Gen Laptop,Intel i7-1355...</td>\n",
       "      <td></td>\n",
       "      <td>89,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...</td>\n",
       "      <td></td>\n",
       "      <td>96,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lenovo IdeaPad Slim 5 Intel Core i7 12th Gen 1...</td>\n",
       "      <td></td>\n",
       "      <td>80,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dell Inspiron 5630 13th Gen Laptop, Intel Core...</td>\n",
       "      <td></td>\n",
       "      <td>89,880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Title of Laptops Ratings     Price\n",
       "0  Dell Inspiron 5430 13th Gen Laptop, Intel i7-1...            86,420\n",
       "1  HP Pavilion 14, 11Th Gen Intel Core I7-16Gb Ra...            79,990\n",
       "2  Lenovo [SmartChoice] IdeaPad Slim 3 Intel Core...            62,990\n",
       "3  Lenovo IdeaPad Gaming 3 Intel Core i7-12700H 1...            98,500\n",
       "4  MSI GF63 Thin, Intel Core i7-11800H, 40CM FHD ...            71,490\n",
       "5  Acer Nitro 5 AN515-58 Gaming Laptop 12th Gen I...          1,04,990\n",
       "6  Dell Vostro 5630 13th Gen Laptop,Intel i7-1355...            89,990\n",
       "7  HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...            96,490\n",
       "8  Lenovo IdeaPad Slim 5 Intel Core i7 12th Gen 1...            80,990\n",
       "9  Dell Inspiron 5630 13th Gen Laptop, Intel Core...            89,880"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the Dataframe from dataset by importing pandas\n",
    "df7=pd.DataFrame({'Title of Laptops':Title,'Ratings':Ratings,'Price':Price})\n",
    "df7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "42c751f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Title of Laptops Ratings     Price\n",
      "0                        Dell Inspiron 5430 13th Gen    None    86,420\n",
      "1  , Intel i7-1360P/16GB/1TB SSD/14.0\" (35.56CMs)...    None    93,990\n",
      "2  Lenovo ThinkPad E14 Intel Core i7 12th Gen 14\"...    None  1,44,990\n",
      "3  (16GB RAM/512GB SSD/Windows 11 Home/MS Office ...    None    79,990\n",
      "4  ASUS ROG Zephyrus G16, 16-inch (40.64 cms) FHD...    None    80,990\n",
      "5                                                       None    98,500\n",
      "6  HP Pavilion 14, 11Th Gen Intel Core I7-16Gb Ra...    None    62,990\n",
      "7  /Intel Iris Xe Graphics/Backlit Keyboard/Alexa...    None  1,04,990\n",
      "8                               Acer Aspire 5 Gaming    None    89,990\n",
      "9  Intel Core i7 13th Gen (8 GB/512 GB SSD/Window...    None    80,990\n"
     ]
    }
   ],
   "source": [
    "print(df7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09869769",
   "metadata": {},
   "source": [
    "# Q8: Write a python program to scrape data for Top 1000 Quotes of All Time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "515c1575",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets import all libraries\n",
    "import pandas as pd\n",
    "import selenium                              #Library that is used to work with selenium\n",
    "from selenium import webdriver               #importing webdriver module from selenium to open automated chrome window\n",
    "from selenium.webdriver.common.by import By  #importing inbuilt class by\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException #for handling the exceptions while scrapping\n",
    "\n",
    "\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "134dc626",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the website page\n",
    "driver.get(\"https://www.azquotes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a75600e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e3cc9720",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on the top Quotes\n",
    "Top_Quotes=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/div[1]/div/div[3]/ul/li[5]/a')\n",
    "Top_Quotes.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c404e463",
   "metadata": {},
   "outputs": [],
   "source": [
    "Quotes=[]\n",
    "Authors=[]\n",
    "Type_of_Quotes=[]\n",
    "\n",
    "start=0\n",
    "end=10\n",
    "for page in range(start,end):\n",
    "    quotes_tags=driver.find_elements(By.XPATH,'//a[@class=\"title\"]')\n",
    "    for i in quotes_tags:\n",
    "        Quotes.append(i.text)\n",
    "    \n",
    "#scrapping the Authors\n",
    "    author_tags=driver.find_elements(By.XPATH,'//div[@class=\"author\"]')\n",
    "    for i in author_tags:\n",
    "        Authors.append(i.text)\n",
    "    \n",
    "#scrapping the Types of Quotes\n",
    "    Type_tags=driver.find_elements(By.XPATH,'//div[@class=\"tags\"]')\n",
    "    for i in Type_tags:\n",
    "        Type_of_Quotes.append(i.text)\n",
    "    \n",
    "    try:\n",
    "        next_button=driver.find_element(By.XPATH,'//li[@class=\"next\"]')\n",
    "        next_button.click()\n",
    "    except NoSuchElementException:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e17a358b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 1000 1000\n"
     ]
    }
   ],
   "source": [
    "print(len(Quotes),len(Authors),len(Type_of_Quotes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d9d0e1b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quotes</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Type_of_Quotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The essence of strategy is choosing what not t...</td>\n",
       "      <td>Michael Porter</td>\n",
       "      <td>Essence, Deep Thought, Transcendentalism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One cannot and must not try to erase the past ...</td>\n",
       "      <td>Golda Meir</td>\n",
       "      <td>Inspiration, Past, Trying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patriotism means to stand by the country. It d...</td>\n",
       "      <td>Theodore Roosevelt</td>\n",
       "      <td>Country, Peace, War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Death is something inevitable. When a man has ...</td>\n",
       "      <td>Nelson Mandela</td>\n",
       "      <td>Inspirational, Motivational, Death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You have to love a nation that celebrates its ...</td>\n",
       "      <td>Erma Bombeck</td>\n",
       "      <td>4th Of July, Food, Patriotic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Regret for the things we did can be tempered b...</td>\n",
       "      <td>Sydney J. Harris</td>\n",
       "      <td>Love, Inspirational, Motivational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>America... just a nation of two hundred millio...</td>\n",
       "      <td>Hunter S. Thompson</td>\n",
       "      <td>Gun, Two, Qualms About</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>For every disciplined effort there is a multip...</td>\n",
       "      <td>Jim Rohn</td>\n",
       "      <td>Inspirational, Greatness, Best Effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The spiritual journey is individual, highly pe...</td>\n",
       "      <td>Ram Dass</td>\n",
       "      <td>Spiritual, Truth, Yoga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>The mind is not a vessel to be filled but a fi...</td>\n",
       "      <td>Plutarch</td>\n",
       "      <td>Inspirational, Leadership, Education</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Quotes             Authors  \\\n",
       "0    The essence of strategy is choosing what not t...      Michael Porter   \n",
       "1    One cannot and must not try to erase the past ...          Golda Meir   \n",
       "2    Patriotism means to stand by the country. It d...  Theodore Roosevelt   \n",
       "3    Death is something inevitable. When a man has ...      Nelson Mandela   \n",
       "4    You have to love a nation that celebrates its ...        Erma Bombeck   \n",
       "..                                                 ...                 ...   \n",
       "995  Regret for the things we did can be tempered b...    Sydney J. Harris   \n",
       "996  America... just a nation of two hundred millio...  Hunter S. Thompson   \n",
       "997  For every disciplined effort there is a multip...            Jim Rohn   \n",
       "998  The spiritual journey is individual, highly pe...            Ram Dass   \n",
       "999  The mind is not a vessel to be filled but a fi...            Plutarch   \n",
       "\n",
       "                               Type_of_Quotes  \n",
       "0    Essence, Deep Thought, Transcendentalism  \n",
       "1                   Inspiration, Past, Trying  \n",
       "2                         Country, Peace, War  \n",
       "3          Inspirational, Motivational, Death  \n",
       "4                4th Of July, Food, Patriotic  \n",
       "..                                        ...  \n",
       "995         Love, Inspirational, Motivational  \n",
       "996                    Gun, Two, Qualms About  \n",
       "997     Inspirational, Greatness, Best Effort  \n",
       "998                    Spiritual, Truth, Yoga  \n",
       "999      Inspirational, Leadership, Education  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df8=pd.DataFrame({\"Quotes\":Quotes,\"Authors\":Authors,\"Type_of_Quotes\":Type_of_Quotes})\n",
    "df8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb138bee",
   "metadata": {},
   "source": [
    "# Q9: Write a python program to display list of respected former Prime Ministers of India(i.e. Name, Born-Dead,\n",
    "Term of office, Remarks) from https://www.jagranjosh.com/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "65250775",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets import all libraries\n",
    "import pandas as pd\n",
    "import selenium                              #Library that is used to work with selenium\n",
    "from selenium import webdriver               #importing webdriver module from selenium to open automated chrome window\n",
    "from selenium.webdriver.common.by import By  #importing inbuilt class by\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException #for handling the exceptions while scrapping\n",
    "time.sleep(5)\n",
    "\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "affb9f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the website page\n",
    "driver.get(\"https://www.jagranjosh.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e55bb25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on the GK\n",
    "gk=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/div/div[1]/div/div[5]/div/div[1]/header/div[3]/ul/li[3]/a')\n",
    "gk.click()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8e6b9996",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on the list of Prime Ministers\n",
    "prime_minister=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div/div[2]/div/div[10]/div/div/ul/li[2]/a\")\n",
    "prime_minister.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "671f3024",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "99a1d392",
   "metadata": {},
   "outputs": [],
   "source": [
    "Prime_Ministers=[]\n",
    "\n",
    "prime_tags=driver.find_elements(By.XPATH,'//div[@class=\"table-box\"]')\n",
    "Prime_Ministers.append(prime_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "19e81aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Prime_Ministers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "939406dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     Prime Ministers\n",
      "0  [<selenium.webdriver.remote.webelement.WebElem...\n"
     ]
    }
   ],
   "source": [
    "df9=pd.DataFrame({\"Prime Ministers\":Prime_Ministers})\n",
    "df9\n",
    "print(df9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62a0696",
   "metadata": {},
   "source": [
    "# Unable to solve this question 9 as could not scrap the data also raised the ticket for this question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe50c90",
   "metadata": {},
   "source": [
    "# Q10: Write a python program to display list of 50 Most expensive cars in the world (i.e.\n",
    "Car name and Price) from https://www.motor1.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c930f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets import all libraries\n",
    "import pandas as pd\n",
    "import selenium                              #Library that is used to work with selenium\n",
    "from selenium import webdriver               #importing webdriver module from selenium to open automated chrome window\n",
    "from selenium.webdriver.common.by import By  #importing inbuilt class by\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException #for handling the exceptions while scrapping\n",
    "time.sleep(10)\n",
    "\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6da500d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the website page\n",
    "driver.get(\"https://www.motor1.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f89305fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching for the cars\n",
    "time.sleep(10)\n",
    "top_cars=driver.find_element(By.XPATH,'/html/body/div[10]/div[2]/div/div/div[3]/div/div/div/form/input')\n",
    "top_cars.send_keys(\"50 most expensive cars\")\n",
    "\n",
    "search=driver.find_element(By.XPATH,'/html/body/div[10]/div[2]/div/div/div[3]/div/div/div/form/button[1]')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "30131889",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on the page link for 50 most expensive cars\n",
    "fifty_car=driver.find_element(By.XPATH,'/html/body/div[10]/div[9]/div/div[1]/div/div/div[2]/div/div[1]/h3/a')\n",
    "fifty_car.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "05f1326f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CAR=[]\n",
    "\n",
    "#Scrapping the data for 50 most expensive cars\n",
    "Car_tags=driver.find_elements(By.XPATH,'//h3[@class=\"subheader\"]')\n",
    "for i in Car_tags[0:50]:\n",
    "    car=i.text\n",
    "    CAR.append(car)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bb5c58ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "print(len(CAR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "13a34926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>50 most expensive cars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>De Tomaso P72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ferrari LaFerrari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pagani Huayra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>McLaren Elva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Czinger 21C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ferrari Monza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gordon Murray T.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Koenigsegg Gemera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Zenvo TSR-S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hennessey Venom F5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bentley Bacalar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Hispano Suiza Carmen Boulogne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bentley Mulliner Batur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Deus Vayanne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SSC Tuatara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Lotus Evija</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Aston Martin Vulcan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Delage D12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>McLaren Speedtail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Rimac Nevera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Pagani Utopia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Pininfarina Battista</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Ferrari FXX K Evo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Gordon Murray T.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Lamborghini Countach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Mercedes-AMG Project One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Aston Martin Victor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Hennessey Venom F5 Roadster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Koenigsegg Jesko</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Aston Martin Valkyrie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>W Motors Lykan Hypersport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>McLaren Solus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Pagani Huayra Roadster BC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Bugatti Chiron Pur Sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Lamborghini Sian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Koenigsegg CC850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Bugatti Chiron Super Sport 300+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Lamborghini Veneno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Bugatti Bolide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Bugatti Mistral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Pagani Huayra Imola</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Bugatti Divo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>SP Automotive Chaos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Pagani Codalunga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Mercedes-Maybach Exelero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Bugatti Centodieci</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Bugatti Chiron Profilée</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Rolls-Royce Sweptail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Bugatti La Voiture Noire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Rolls-Royce Boat Tail*</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             50 most expensive cars\n",
       "0                     De Tomaso P72\n",
       "1                 Ferrari LaFerrari\n",
       "2                     Pagani Huayra\n",
       "3                      McLaren Elva\n",
       "4                       Czinger 21C\n",
       "5                     Ferrari Monza\n",
       "6                Gordon Murray T.33\n",
       "7                 Koenigsegg Gemera\n",
       "8                       Zenvo TSR-S\n",
       "9                Hennessey Venom F5\n",
       "10                  Bentley Bacalar\n",
       "11    Hispano Suiza Carmen Boulogne\n",
       "12           Bentley Mulliner Batur\n",
       "13                     Deus Vayanne\n",
       "14                      SSC Tuatara\n",
       "15                      Lotus Evija\n",
       "16              Aston Martin Vulcan\n",
       "17                       Delage D12\n",
       "18                McLaren Speedtail\n",
       "19                     Rimac Nevera\n",
       "20                    Pagani Utopia\n",
       "21             Pininfarina Battista\n",
       "22                Ferrari FXX K Evo\n",
       "23               Gordon Murray T.50\n",
       "24             Lamborghini Countach\n",
       "25         Mercedes-AMG Project One\n",
       "26              Aston Martin Victor\n",
       "27      Hennessey Venom F5 Roadster\n",
       "28                 Koenigsegg Jesko\n",
       "29            Aston Martin Valkyrie\n",
       "30        W Motors Lykan Hypersport\n",
       "31                    McLaren Solus\n",
       "32        Pagani Huayra Roadster BC\n",
       "33         Bugatti Chiron Pur Sport\n",
       "34                 Lamborghini Sian\n",
       "35                 Koenigsegg CC850\n",
       "36  Bugatti Chiron Super Sport 300+\n",
       "37               Lamborghini Veneno\n",
       "38                   Bugatti Bolide\n",
       "39                  Bugatti Mistral\n",
       "40              Pagani Huayra Imola\n",
       "41                     Bugatti Divo\n",
       "42              SP Automotive Chaos\n",
       "43                 Pagani Codalunga\n",
       "44         Mercedes-Maybach Exelero\n",
       "45               Bugatti Centodieci\n",
       "46          Bugatti Chiron Profilée\n",
       "47             Rolls-Royce Sweptail\n",
       "48         Bugatti La Voiture Noire\n",
       "49           Rolls-Royce Boat Tail*"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the DataFrame \n",
    "\n",
    "df10=pd.DataFrame({\"50 most expensive cars\":CAR})\n",
    "df10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1c5519",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ecad62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8976ee33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
